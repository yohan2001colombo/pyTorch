{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOCU6FcMO1L+Ahr20IVRzWk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yohan2001colombo/pyTorch/blob/main/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "gZpA6XlqZJYg"
      },
      "outputs": [],
      "source": [
        "# Import the libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert MNIST Image files into a Tensor of 4-Dimensions (# of Images, Height, Width, colour channel)\n",
        "\n",
        "transform = transforms.ToTensor()"
      ],
      "metadata": {
        "id": "GER2qHIqni1u"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Data\n",
        "train_data = datasets.MNIST(root='cnn_data',train=True, download=True,transform = transform)"
      ],
      "metadata": {
        "id": "n22k2QX8ozJv"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader_pytorch = DataLoader(train_data, batch_size = 1, shuffle = True)\n",
        "# Create a figure to display the images\n",
        "plt.figure(figsize=(15, 3))\n",
        "\n",
        "# Print the first few images in a row\n",
        "for i, (image, label) in enumerate(train_loader_pytorch):\n",
        "    if i < 5:  # Print the first 5 samples\n",
        "        plt.subplot(1, 5, i + 1)\n",
        "        plt.imshow(image[0].squeeze(), cmap='gray')\n",
        "        plt.title(f\"Label: {label.item()}\")\n",
        "        plt.axis('off')\n",
        "    else:\n",
        "        break  # Exit the loop after printing 5 samples\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "id": "mGnCIDAwWUhY",
        "outputId": "7796b052-8a5f-4d23-ed62-b8b21a8a5fbf"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x300 with 5 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABb4AAAExCAYAAACzsrRmAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAI1VJREFUeJzt3XuQluV5P/BrAUVAAiigRIOH0QTxEFIRkRx8iQYxNg5OKOrUU42ptdpYjJBq1V2amOCBhihJZKJijLQSLdhQK6bV3TShHrAUo1aUGIlBDcpBwQPHfX9/5OdOjMTnJjy7+743n89MZuLLd+/r4s1yZ/nO425DtVqtBgAAAAAAZKJLZy8AAAAAAABlUnwDAAAAAJAVxTcAAAAAAFlRfAMAAAAAkBXFNwAAAAAAWVF8AwAAAACQFcU3AAAAAABZUXwDAAAAAJAVxTcAAAAAAFlRfO/kli9fHg0NDXH99deXdmZLS0s0NDRES0tLaWcCOyd3FFDL3FFALXNHAbXMHUVHUHzXodtuuy0aGhriscce6+xV2sUzzzwTEydOjFGjRsVuu+0WDQ0NsXz58s5eC0iU+x31jjlz5sQxxxwTvXr1ir59+8aoUaPiwQcf7Oy1gAI7yx31js985jPR0NAQF110UWevAiTYGe6o//zP/4zRo0dH//79o2/fvjFixIj4wQ9+0NlrAQlyv6PmzZsXJ5xwQnzwgx+M7t27x7777hvjx4+PJ598srNX44+k+KbmPPTQQ3HDDTfE+vXr45BDDunsdQDeo6mpKU4//fT40Ic+FP/4j/8YX/va1+KII46IF198sbNXA2gzd+7ceOihhzp7DYA2P/rRj2LMmDGxadOmaGpqiquvvjp69OgRZ511Vnzzm9/s7PWAndwTTzwR/fr1i4svvji+853vxAUXXBD/+7//GyNGjIjHH3+8s9fjj9CtsxeA33fyySfHa6+9Fr17947rr78+lixZ0tkrAbR5+OGH4x/+4R9i2rRpMXHixM5eB2CbNmzYEF/+8pfjK1/5Slx11VWdvQ5ARETMmDEjBg0aFA8++GB07949IiLOP//8GDJkSNx2222+tgI61ba+ZjrvvPNi3333je9+97tx0003dcJW7AhPfGdq06ZNcdVVV8WRRx4Zffr0iV69esUnP/nJaG5u/oMf881vfjP222+/6NGjRxx77LHb/Fc5li5dGuPHj4899tgjdttttxg+fHj86Ec/KtznrbfeiqVLl8aqVasKs3vssUf07t27MAfUr3q+o6ZPnx577713XHzxxVGtVuONN94o/BigvtTzHfWOa6+9NlpbW+PSSy9N/higPtTzHbVu3bro169fW+kdEdGtW7fo379/9OjRo/DjgdpXz3fUtgwcODB69uwZr7322h/18XQuxXem1q1bFzfffHNUKpW45pproqmpKV599dU44YQTtvkE9e233x433HBDXHjhhXHZZZfFk08+GZ/+9Kdj5cqVbZmnnnoqRo4cGU8//XT83d/9XUybNi169eoV48aNi3nz5r3vPo8++mgccsghMWPGjLJ/q0Adquc76oEHHoijjjoqbrjhhhgwYED07t07Bg0a5H6DjNTzHRUR8cILL8TUqVPjmmuuUSRBhur5jqpUKvHUU0/FlVdeGb/4xS/iueeei69+9avx2GOPxeTJk7f7vQBqTz3fUe947bXX4tVXX40nnngizjvvvFi3bl0cd9xxyR9PDalSd2bNmlWNiOqiRYv+YGbLli3VjRs3vuu1tWvXVvfaa6/queee2/ba888/X42Iao8ePaorVqxoe/2RRx6pRkR14sSJba8dd9xx1cMPP7y6YcOGttdaW1uro0aNqh588MFtrzU3N1cjotrc3Pye1xobG7fr93rddddVI6L6/PPPb9fHAZ0n5ztqzZo11Yio7rnnntXdd9+9et1111XnzJlTHTt2bDUiqjfddNP7fjzQ+XK+o94xfvz46qhRo9r+OSKqF154YdLHAp0r9zvqjTfeqE6YMKHa0NBQjYhqRFR79uxZveeeewo/Fuh8ud9R7/jIRz7Sdkftvvvu1SuuuKK6devW5I+ndnjiO1Ndu3aNXXfdNSIiWltbY82aNbFly5YYPnx4LF68+D35cePGxT777NP2zyNGjIijjz46/v3f/z0iItasWRMPPvhgTJgwIdavXx+rVq2KVatWxerVq+OEE06IZcuWve8PdatUKlGtVqOpqanc3yhQl+r1jnrn25qsXr06br755rj00ktjwoQJce+998bQoUPja1/72va+FUANqtc7KiKiubk5/uVf/iWmT5++fb9poG7U8x3VvXv3+PCHPxzjx4+Pf/7nf4477rgjhg8fHmeccUY8/PDD2/lOALWonu+od8yaNSsWLFgQ3/nOd+KQQw6Jt99+O7Zu3Zr88dQOP9wyY9///vdj2rRpsXTp0ti8eXPb6wcccMB7sgcffPB7Xvvwhz8cP/zhDyMi4he/+EVUq9W48sor48orr9zmvFdeeeVdlxXA+6nHO+qdbxmwyy67xPjx49te79KlS5x66qnR2NgYL7zwQgwePHiH5gCdrx7vqC1btsSXvvSlOPPMM+Ooo47aobOA2laPd1RExEUXXRQPP/xwLF68OLp0+e1zeBMmTIhDDz00Lr744njkkUd2eAbQ+er1jnrHMccc0/bfTzvttDjkkEMiIuL6668vbQYdQ/GdqTvuuCPOOeecGDduXEyaNCkGDhwYXbt2jW984xvx3HPPbfd5ra2tERFx6aWXxgknnLDNzEEHHbRDOwM7j3q9o975QSp9+/aNrl27vuvXBg4cGBERa9euVXxDnavXO+r222+PZ555JmbOnBnLly9/16+tX78+li9f3vYDmoD6Va931KZNm+KWW26JyZMnt5XeEb99oODEE0+MGTNmxKZNm9qeFAXqU73eUX9Iv3794tOf/nTMnj1b8V2HFN+Zuvvuu+PAAw+MuXPnRkNDQ9vrjY2N28wvW7bsPa89++yzsf/++0dExIEHHhgRv/2i5Pjjjy9/YWCnUq93VJcuXWLYsGGxaNGi9/zF7KWXXoqIiAEDBrTbfKBj1Osd9cILL8TmzZvj4x//+Ht+7fbbb4/bb7895s2bF+PGjWu3HYD2V6931OrVq2PLli3b/HYBmzdvjtbWVt9KADJQr3fU+3n77bfj9ddf75TZ7Bjf4ztT7zyJWK1W21575JFH4qGHHtpm/p577nnX90R69NFH45FHHokTTzwxIn77JGOlUomZM2fGyy+//J6Pf/XVV993n7feeiuWLl0aq1at2u7fC5Cfer6jTj311Ni6dWt8//vfb3ttw4YNMXv27Bg6dGh88IMfLDwDqG31ekeddtppMW/evPf8JyLis5/9bMybNy+OPvro9z0DqH31ekcNHDgw+vbtG/PmzYtNmza1vf7GG2/E/PnzY8iQIW3fVg6oX/V6R0X89lum/L7ly5fHAw88EMOHDy/8eGqPJ77r2K233hoLFix4z+sXX3xx/Omf/mnMnTs3TjnllDjppJPi+eefj5tuuimGDh3a9sPZftdBBx0Un/jEJ+KCCy6IjRs3xvTp02PPPfeMyZMnt2W+/e1vxyc+8Yk4/PDD44tf/GIceOCBsXLlynjooYdixYoV8fjjj//BXR999NEYPXp0NDY2Fv5Agddffz1uvPHGiIhYuHBhRETMmDEj+vbtG3379o2LLroo5e0BOlmud9T5558fN998c1x44YXx7LPPxuDBg+MHP/hB/OpXv4r58+env0FAp8rxjhoyZEgMGTJkm792wAEHeNIb6kiOd1TXrl3j0ksvjSuuuCJGjhwZZ511VmzdujVuueWWWLFiRdxxxx3b9yYBnSbHOyoi4vDDD4/jjjsuhg0bFv369Ytly5bFLbfcEps3b46pU6emv0HUDMV3Hfvud7+7zdfPOeecOOecc+I3v/lNzJw5M+6///4YOnRo3HHHHXHXXXdFS0vLez7mrLPOii5dusT06dPjlVdeiREjRsSMGTNi0KBBbZmhQ4fGY489FlOmTInbbrstVq9eHQMHDoyPfexjcdVVV5X2+1q7du17fmDBtGnTIiJiv/32U3xDncj1jurRo0c8+OCDMXny5Lj11lvjzTffjGHDhsW99977B7/nHFB7cr2jgDzkekf9/d//fRxwwAHxrW99K6ZMmRIbN26MI444Iu6+++74/Oc/X9ocoH3lekddcMEFce+998aCBQti/fr1MXDgwBgzZkxcfvnlcfjhh5c2h47TUP3df/cAAAAAAADqnO/xDQAAAABAVhTfAAAAAABkRfENAAAAAEBWFN8AAAAAAGRF8Q0AAAAAQFYU3wAAAAAAZEXxDQAAAABAVrqlBhsaGtpzD6BOVavVzl4hItxRwLa5o4Ba5o4Capk7CqhlKXeUJ74BAAAAAMiK4hsAAAAAgKwovgEAAAAAyIriGwAAAACArCi+AQAAAADIiuIbAAAAAICsKL4BAAAAAMiK4hsAAAAAgKwovgEAAAAAyIriGwAAAACArCi+AQAAAADIiuIbAAAAAICsKL4BAAAAAMiK4hsAAAAAgKwovgEAAAAAyIriGwAAAACArCi+AQAAAADIiuIbAAAAAICsdOvsBQCA7dPc3FyYqVQqSWdNmTKlMNPU1JR0FgAAANQKT3wDAAAAAJAVxTcAAAAAAFlRfAMAAAAAkBXFNwAAAAAAWVF8AwAAAACQFcU3AAAAAABZUXwDAAAAAJAVxTcAAAAAAFnp1tkLAAC/1dzcnJSrVCqlzTz22GNLOwsAAABqhSe+AQAAAADIiuIbAAAAAICsKL4BAAAAAMiK4hsAAAAAgKwovgEAAAAAyIriGwAAAACArCi+AQAAAADIiuIbAAAAAICsKL4BAAAAAMhKQ7VarSYFGxraexfqxP7775+UW7hwYWHmpZdeSjrrqKOOSsrR8RKvkHbnjqLWNTc3F2YqlUr7L/J7cv+z444Capk7Cqhl7iiglqXcUZ74BgAAAAAgK4pvAAAAAACyovgGAAAAACArim8AAAAAALKi+AYAAAAAICuKbwAAAAAAsqL4BgAAAAAgK4pvAAAAAACy0q2zF6D+7L333km5vfbaq5QMQK1rbm4uzFQqlcJMS0tL0rwpU6aUdhYAsHNI+frhU5/6VNJZhx12WGFm7ty5SWe1trYWZmbNmlWYWbp0adK8devWJeWAjtW9e/fCzGc/+9mks8aMGVOY+au/+quks1544YXCzB133FGYmTFjRtK8l19+OSlHGk98AwAAAACQFcU3AAAAAABZUXwDAAAAAJAVxTcAAAAAAFlRfAMAAAAAkBXFNwAAAAAAWVF8AwAAAACQFcU3AAAAAABZaahWq9WkYENDe+9CnZg+fXpS7qKLLiptZrdu3Uo7i3IlXiHtzh1Fe+joz2+fx+VzRwG1zB1Fkd69eyfl7r///sLMRz/60cJMjx49kubVogULFiTlLr/88sLMkiVLdnCbPLijKMvee+9dmJk/f35h5k/+5E/KWCciIt58882kXK9evUqZd+SRRybl3D/pUu4oT3wDAAAAAJAVxTcAAAAAAFlRfAMAAAAAkBXFNwAAAAAAWVF8AwAAAACQFcU3AAAAAABZUXwDAAAAAJAVxTcAAAAAAFlRfAMAAAAAkJVunb0A9WfQoEGlnfW9732vtLMAIiKampqSco2Nje27yO9paGjo0HlAx/vABz5QmPn85z+fdNb//d//FWYeeeSRpLPq2T777FOY+dnPflaYWbZsWdK8Pn36FGaOPvropLOgDJMnT07KjRw5sp03ebdf//rXhZkHHngg6awnnniiMHP11VcXZsaOHZs0b9GiRYWZJUuWJJ0FO7u+ffsm5VL+f7hnz56FmdQ/mzfeeGNhJuXuiYi49dZbCzOHHXZY0ll0PE98AwAAAACQFcU3AAAAAABZUXwDAAAAAJAVxTcAAAAAAFlRfAMAAAAAkBXFNwAAAAAAWVF8AwAAAACQFcU3AAAAAABZ6dbZC1B/GhoaSsu9+eabO7oOwLs0NjZ2+MzRo0d3+Eyg9sydO7cwc9xxxyWd9fDDDxdmTjrppKSz1qxZk5SrRXfffXdhZv/99y8lExFx7LHHJuWgDCNGjCjMXHrppaXNe+655woz3/rWt5LOuv322wsz69atSzorRcrXd7vttlvSWZ/73OdKmQdEnHXWWUm5nj17FmamTZtWmJk8eXLSvBQjR45Myg0YMKC0mXQ8T3wDAAAAAJAVxTcAAAAAAFlRfAMAAAAAkBXFNwAAAAAAWVF8AwAAAACQFcU3AAAAAABZUXwDAAAAAJAVxTcAAAAAAFlRfAMAAAAAkJVunb0AtaV79+6FmX79+iWdVa1WS8kAO4dKpVKYaW5uLm1eS0tLYWbKlCmlnQXUpv79+yflfvWrXxVmevbsuaPrtNlll10KMw0NDaXNK1PK14rPPPNM0lkDBgwozLz++uuFmZNPPjlp3k9/+tOkHBS57LLLCjNf+cpXCjMpfz+LiNi0aVNh5pRTTinMPPnkk0nzypRyD5d537344oulnQU7uz/7sz8r7azJkyeXdlaPHj0KM1//+teTztprr70KM/PmzSvM/PKXv0yaR7k88Q0AAAAAQFYU3wAAAAAAZEXxDQAAAABAVhTfAAAAAABkRfENAAAAAEBWFN8AAAAAAGRF8Q0AAAAAQFYU3wAAAAAAZKVbZy9AbRk4cGBhZvTo0R2wCZCL5ubmpFylUillXktLS1LOXQb5GzBgQGHmvvvuSzqrZ8+ehZlqtVqYWblyZdK8m266qTCzevXqpLPK0qtXr6TcDTfcUJhJ+d8m1Y9//OPCzH/913+VNg9SrFq1qjDTp0+fwkzKvRIR8fDDDxdmnnzyyaSzyjJ48OCk3OLFiwszvXv33tF1tmsekObOO+9Myi1YsKAw061bcUV5yimnJM2bNGlSYebII49MOmvt2rWFmcbGxsLMunXrkuZRLk98AwAAAACQFcU3AAAAAABZUXwDAAAAAJAVxTcAAAAAAFlRfAMAAAAAkBXFNwAAAAAAWVF8AwAAAACQFcU3AAAAAABZ6dbZCwBQv5qbmwszlUqltHktLS2FmSlTppQ2D6hd/fv3L8zcd999hZkjjzyyjHUiImLq1KmFmcsvv7y0eR0t9X4944wzSpu5bNmywsyECRNKmwdlmTNnTmFm0qRJhZmDDjooad7s2bOTch3pU5/6VFJujz32KGXeU089lZSbOXNmKfOAiG9/+9tJuVNOOaUwc+ONNxZm/vIv/zJpXplWrlxZSobO4YlvAAAAAACyovgGAAAAACArim8AAAAAALKi+AYAAAAAICuKbwAAAAAAsqL4BgAAAAAgK4pvAAAAAACyovgGAAAAACArim8AAAAAALLSrbMXoP40NDSUdtaSJUtKOwsoV6VSKSWTasqUKYWZpqam0uYBtenEE09Myl177bWFmcMOO2xH12lz//33F2auuOKK0uZ1tC984QuFmUsuuaS0ea+88kpSbvTo0aXNhI60bt26wszTTz9dmDnooIOS5q1fvz4pV+QjH/lIUi7lz+bEiRN3dJ02GzduLMycd955SWe99NJLO7oO8P9df/31Sbm//du/Lcx06VL8bG61Wk2aV6YhQ4YUZhYvXlyYGTNmTNK8pUuXJuVI44lvAAAAAACyovgGAAAAACArim8AAAAAALKi+AYAAAAAICuKbwAAAAAAsqL4BgAAAAAgK4pvAAAAAACyovgGAAAAACAr3Tp7AWrLSSedVJipVqulzRs2bFhSbvbs2aXNhJ1dU1NTUq6xsbGUeS0tLUm51L1qUaVSKcykvJ8p55StoaGhw2eSn6uvvjop171798LM+eefn3TW7rvvnpQry7Rp0wozra2tpc0bMmRIYeb1119POuvP//zPCzMTJ04szJR5X8yaNSsp9+KLL5Y2E2rNz3/+88LM5z73uaSzLrnkksLMmjVrCjNz5sxJmtenT5+kXIqUv18ec8wxhZklS5aUsA3wjtNPP70wc/HFFyedVYt/53jssceScsOHDy/M7LPPPoWZSZMmJc37whe+kJQjjSe+AQAAAADIiuIbAAAAAICsKL4BAAAAAMiK4hsAAAAAgKwovgEAAAAAyIriGwAAAACArCi+AQAAAADIiuIbAAAAAICsdOvsBagtBx98cIfOmzNnTofOg9xVKpXCTGNjY2nzWlpaCjOjR48ubV6KlPcgIu19SD2rnjU1NZWSYee2zz77JOXOPvvsdt6k/Rx//PGFmf/4j/8obd6QIUMKM/PmzSttXkd77bXXOnsF6HQLFiwozEyaNCnprOHDh5cyr0wvv/xyUu6MM84ozCxZsmQHtwG217PPPluYefvtt5PO6tWrV2Fm7NixhZmFCxcmzUuxefPmpNz8+fMLMylfJ5555plJ866++urCzC9/+cuks/DENwAAAAAAmVF8AwAAAACQFcU3AAAAAABZUXwDAAAAAJAVxTcAAAAAAFlRfAMAAAAAkBXFNwAAAAAAWVF8AwAAAACQFcU3AAAAAABZ6dbZC7Bz+81vftPZK0BdqFQqSbnm5ubSZra0tBRmRo8eXdq8FE1NTYWZxsbG9l8kIynvV8r7zs5tjz326OwV2t0555xTmJk/f35h5mc/+1nSvA0bNiTlypIy77rrrks66/HHHy/M/Nu//VvSWZCzhQsXFmZSvh6LiBgzZswObrN9nn322cJM6tcPZX79CpTnf/7nfwozH/jABzpgk/YxceLEpNxnPvOZUub9/Oc/T8qtXbu2lHn8lie+AQAAAADIiuIbAAAAAICsKL4BAAAAAMiK4hsAAAAAgKwovgEAAAAAyIriGwAAAACArCi+AQAAAADIiuIbAAAAAICsdOvsBagtl1xySWGmtbU16ay77rqrMLNixYqksyBnlUqlMNPc3FzavJaWlqTc6NGjS5tZlsbGxs5eITupnw/wfvbbb7/OXqHdDRw4sDCT8ufpySefTJq3zz77JOXKcu211xZm3MHQ8R5//PGk3JgxY9p5k3ebOnVqYebOO+/sgE2AnUnXrl2Tcn/xF39RmLnggguSzqpWq4WZjRs3FmbOPvvspHlr165NypHGE98AAAAAAGRF8Q0AAAAAQFYU3wAAAAAAZEXxDQAAAABAVhTfAAAAAABkRfENAAAAAEBWFN8AAAAAAGRF8Q0AAAAAQFYU3wAAAAAAZKVbZy9AbWltbS3MVKvVDtgEdh6NjY0dOm/06NEdOi9Vc3Nzh85raWkpzFQqlQ4/q6PV6ucD9eW4445Lyv3N3/xNYeZjH/vYjq5T00aMGJGU69+/f2kzV65cWZi5/vrrS5sHpBk5cmRh5ktf+lIHbLL9DjzwwM5eAchMly7Fz+ZOnDgx6axrrrlmR9dps2HDhsLMRRddVJh56qmnyliH7eSJbwAAAAAAsqL4BgAAAAAgK4pvAAAAAACyovgGAAAAACArim8AAAAAALKi+AYAAAAAICuKbwAAAAAAsqL4BgAAAAAgK906ewGAnFUqlVIyqRoaGko7qyxNTU1JuTLfh46eV9ZZU6ZMKeWciPT3HcqwatWqpFxjY2M7b9K5rrzyysLM2LFjS5v361//Oil36KGHFmbWr1+/o+sAv2PMmDGFmWnTphVmunfvnjRv48aNhZljjjmmMHP22WcnzZs4cWJhZt99900669xzz03KAXn78pe/XJiZOnVqafOWL1+elPv6179emJk1a9YObkN78cQ3AAAAAABZUXwDAAAAAJAVxTcAAAAAAFlRfAMAAAAAkBXFNwAAAAAAWVF8AwAAAACQFcU3AAAAAABZUXwDAAAAAJCVbp29AEDOKpVKh86rVquFmZaWlqSzfvKTnxRmjj322MJMR78HnSHlPU15P5uamnZ8GaBdHHHEEYWZyy+/vDCzyy67JM3bvHlzYebss89OOmv9+vVJOaA83/jGNwozhx56aGFmy5YtSfPOO++8wsySJUtKyUREvP7664WZc889N+msPffcszCzevXqpLOA2jR37tzCzLhx4wozGzduTJr36KOPFmYaGxuTzkr9+zO1yRPfAAAAAABkRfENAAAAAEBWFN8AAAAAAGRF8Q0AAAAAQFYU3wAAAAAAZEXxDQAAAABAVhTfAAAAAABkRfENAAAAAEBWFN8AAAAAAGSlW2cvQG356U9/Wpj55Cc/mXTWsGHDCjN9+/ZNOuu1115LykGtaWlpKcw0Nja2/yK/o1KplJqrNSnveUTET37yk9LOSs0BtWfQoEFJubvuuqsws9tuu+3oOm1OP/30wkxzc3Np84ByDRgwoJRzUr5eiYiYPXt2KfNSrVixojCz7777Jp01derUwswXv/jFpLOA8qT8Gf7e976XdNbxxx+/o+tERMSiRYuScscee2wp86h/nvgGAAAAACArim8AAAAAALKi+AYAAAAAICuKbwAAAAAAsqL4BgAAAAAgK4pvAAAAAACyovgGAAAAACArim8AAAAAALLSrbMXoLa89NJLhZlqtZp0Vr9+/Qozu+66a9JZUK9aWloKM6NHjy7MNDY2Js2rVCpJuY40ZcqU0s5KeT9TMsDOYeDAgYWZp59+OumsPn36FGZaW1sLM+PHj0+a96//+q9JOaA23XbbbYWZK664ojDz8ssvl7BN+QYPHlyY2bp1a9JZvXr12tF1gO00ZsyYwsw111xTmDniiCPKWCciImbMmFGY+epXv1raPHYOnvgGAAAAACArim8AAAAAALKi+AYAAAAAICuKbwAAAAAAsqL4BgAAAAAgK4pvAAAAAACyovgGAAAAACArim8AAAAAALKi+AYAAAAAICvdOnsBasupp55amKlWq0lnNTc3F2ZeeeWVpLMgZy0tLaVkAHi3mTNnFmb69OmTdFbK1yxTp04tzCxevDhpXmtra1IOqE3//d//XZh55plnCjPjx49PmnffffcVZnr27FmYGTduXNK8448/vjDTtWvXpLM2b96clINc7bnnnkm5k08+uTBz5plnJp11zDHHFGZ23XXXpLNS/PVf/3Vh5oc//GFhZu3atWWsw07EE98AAAAAAGRF8Q0AAAAAQFYU3wAAAAAAZEXxDQAAAABAVhTfAAAAAABkRfENAAAAAEBWFN8AAAAAAGRF8Q0AAAAAQFYaqtVqNSnY0NDeu1ADFi1aVJjZe++9k84aO3ZsYeapp55KOovalXiFtDt3FLAt7qh8nXjiiYWZOXPmFGZWr15d2rznn3++MDNgwICkeStWrEjKUd/cUTu3kSNHFmbuvPPOpLMGDx68o+uUbvHixUm5k046qTCzcuXKHV2HP4I7ascdf/zxhZnGxsaks0aNGrWj65Tuox/9aFIupfuplc836kfK54wnvgEAAAAAyIriGwAAAACArCi+AQAAAADIiuIbAAAAAICsKL4BAAAAAMiK4hsAAAAAgKwovgEAAAAAyIriGwAAAACArDRUq9VqUrChob13AepQ4hXS7txRwLa4o/LVvXv3wsyPf/zjwsyWLVuS5o0dO7Yws3nz5qSz4B3uKIp86EMfSspddtllhZnTTjutMLNkyZKkeffcc09h5p/+6Z+Szlq1alVSjo7njtpxgwYNKszMnj076ayFCxcWZj7+8Y8nnXXrrbcWZubNm1eYeeutt5Lm1crnEnlJ+bzyxDcAAAAAAFlRfAMAAAAAkBXFNwAAAAAAWVF8AwAAAACQFcU3AAAAAABZUXwDAAAAAJAVxTcAAAAAAFlRfAMAAAAAkBXFNwAAAAAAWWmoVqvVpGBDQ3vvAtShxCuk3bmjgG1xRwG1zB0F1DJ3FFDLUu4oT3wDAAAAAJAVxTcAAAAAAFlRfAMAAAAAkBXFNwAAAAAAWVF8AwAAAACQFcU3AAAAAABZUXwDAAAAAJAVxTcAAAAAAFlRfAMAAAAAkBXFNwAAAAAAWVF8AwAAAACQFcU3AAAAAABZUXwDAAAAAJAVxTcAAAAAAFlRfAMAAAAAkBXFNwAAAAAAWVF8AwAAAACQFcU3AAAAAABZUXwDAAAAAJAVxTcAAAAAAFlRfAMAAAAAkBXFNwAAAAAAWVF8AwAAAACQFcU3AAAAAABZUXwDAAAAAJAVxTcAAAAAAFlRfAMAAAAAkJWGarVa7ewlAAAAAACgLJ74BgAAAAAgK4pvAAAAAACyovgGAAAAACArim8AAAAAALKi+AYAAAAAICuKbwAAAAAAsqL4BgAAAAAgK4pvAAAAAACyovgGAAAAACAr/w/6SpDLCR7rOQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = datasets.MNIST(root='cnn_data',train=False, download=True, transform = transform)"
      ],
      "metadata": {
        "id": "7A_-i_enpVf4"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cix41wDYp4PJ",
        "outputId": "52a2f212-addd-40e3-971b-2cbcd01d41f5"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: cnn_data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "XfjicJNbqfAp",
        "outputId": "2efb96b9-0b0a-47be-f518-b428cc76f4ce"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/cnn_data'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5uTy_Xmqihf",
        "outputId": "ad29cdcd-3adb-406a-fa51-7b9fd4659ebe"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mcnn_data\u001b[0m/  \u001b[01;34mMNIST\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls MNIST/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8HHhfTBqlls",
        "outputId": "5c6afc0e-4b3e-4005-fec2-2c909d539662"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mraw\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHN5pq7CqoDY",
        "outputId": "853ff398-ca9a-4eae-a107-21dce5dc9e5d"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mcnn_data\u001b[0m/  \u001b[01;34mMNIST\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mh4vgxlbq5gx",
        "outputId": "8089145e-e34b-413b-f465-f9992447b11b"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mcnn_data\u001b[0m/  \u001b[01;34mMNIST\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsbqEfSrrF3H",
        "outputId": "b61b9975-893d-4a08-c664-11ebfae18a75"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: cnn_data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a small batch size for images... lets say 10\n",
        "train_loader = DataLoader(train_data, batch_size = 10, shuffle = True)\n",
        "test_loader = DataLoader(test_data, batch_size = 10, shuffle=True)"
      ],
      "metadata": {
        "id": "9k-BDmHCrgrh"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Our CNN model\n",
        "# Describe convolutional layer and what it's doing (2 CNN layer)\n",
        "# futher datails https://www.datacamp.com/tutorial/introduction-to-convolutional-neural-networks-cnns?utm_source=google&utm_medium=paid_search&utm_campaignid=19589720824&utm_adgroupid=157156376071&utm_device=c&utm_keyword=&utm_matchtype=&utm_network=g&utm_adpostion=&utm_creative=684592140425&utm_targetid=aud-1459190388940:dsa-2218886984380&utm_loc_interest_ms=&utm_loc_physical_ms=9199150&utm_content=ps-other~apac-en~dsa~tofu~tutorial-machine-learning&accountid=9624585688&utm_campaign=230119_1-ps-other~dsa~tofu_2-b2c_3-apac_4-prc_5-na_6-na_7-le_8-pdsh-go_9-nb-e_10-na_11-na&gad_source=1&gad_campaignid=19589720824&gclid=Cj0KCQjwjJrCBhCXARIsAI5x66Uf0XuTUPi3M_b9uvoF7ASr7Er9mzQftB0aH8uHcmlelHHG2czVAO8aAu6DEALw_wcB\n",
        "\n",
        "\n",
        "conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=3, stride=1)\n",
        "conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=3, stride=1)"
      ],
      "metadata": {
        "id": "9sg6HsmRs_2f"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grab 1 MNIST record/Image\n",
        "for i, (X_train, y_train) in enumerate(train_data):\n",
        "  break"
      ],
      "metadata": {
        "id": "Dn50ViSC4IlF"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape\n",
        "# torch.Size([1, 28, 28]) ==> 1 Image 28*28 pixels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exlpzhJM4wvY",
        "outputId": "daee319b-13be-46de-b55f-b12c8ff6dc5c"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = X_train.view(1,1,28,28)\n",
        "# 1 Batch 1 Image 28*28 Image Pixel"
      ],
      "metadata": {
        "id": "LxqjpzRD5e4a"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform our first convolution\n",
        "x = F.relu(conv1(x)) # Recitified Linear Unit for our activation function\n"
      ],
      "metadata": {
        "id": "8X1Kh9EM6LTJ"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1 Single Image, 6  is the filters we asked for 26*26 pixels\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRPwKIRo65xR",
        "outputId": "c21b9430-c824-483e-8f41-e32ee2575ba2"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 6, 26, 26])"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pass through the pooling layer\n",
        "x = F.max_pool2d(x,2,2) # kernel of 2 and stride of 2"
      ],
      "metadata": {
        "id": "Zw9ZU9SX8qfG"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape\n",
        "# 26/2 = 13"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Al2PZu19Rsf",
        "outputId": "559935f2-9b67-4e25-81ce-b861903508cf"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 6, 13, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Do our second convolution\n",
        "x = F.relu(conv2(x))"
      ],
      "metadata": {
        "id": "4HQpDSuw9afD"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Again we didn't set padding so we lose 2 pixels around the outside of the image\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZjXrsn5-Nu3",
        "outputId": "5afe77b6-22c2-4356-f86c-8320f4e12662"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 16, 11, 11])"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pooling Layer\n",
        "x = F.max_pool2d(x,2,2)"
      ],
      "metadata": {
        "id": "RJ2HCLwr-M2k"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 11/2 = 5.5 but we have to round down because you can't invent data to round up # lose data in pooling\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7UyZaZl-ncv",
        "outputId": "dae46b42-e094-435f-e085-8e43c17405c0"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 16, 5, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1 Image ==> Conv1 ==> Padding ==> Conv2 ==> Padding\n",
        "# Model Class\n",
        "class convolutionalNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(1,6,3,1)\n",
        "    self.conv2 = nn.Conv2d(6,16,3,1)\n",
        "    # Fully connected layer\n",
        "    self.fc1 = nn.Linear(5*5*16,120)\n",
        "    self.fc2 = nn.Linear(120,84)\n",
        "    self.fc3 = nn.Linear(84,10)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = F.max_pool2d(x,2,2) # 2x2 kernel and stride 2\n",
        "    x = F.relu(self.conv2(x))\n",
        "    x = F.max_pool2d(x,2,2)\n",
        "\n",
        "    # Re-View to flatten it out\n",
        "    x = x.view(-1,5*5*16) # negative one so that we can vary the batch size\n",
        "\n",
        "    # Fully connected layer\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "\n",
        "    return F.log_softmax(x,dim=1)\n"
      ],
      "metadata": {
        "id": "iIlsfYgu_H6J"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an Instance of our model\n",
        "torch.manual_seed(42)\n",
        "model = convolutionalNetwork()\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nqes7IX2CxJv",
        "outputId": "59b343ab-eacb-4ace-e249-9b8444e23e07"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "convolutionalNetwork(\n",
              "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # smaller the laerning rate longer its gonna take to train\n"
      ],
      "metadata": {
        "id": "mkvS8tgNDItY"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5RpO_y4Ke9b",
        "outputId": "fbbbdf31-19ef-425e-b945-6b10f0e1ab9b"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "convolutionalNetwork(\n",
              "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "# create variales to track things\n",
        "epochs = 5\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "train_correct = []\n",
        "test_correct = []\n",
        "\n",
        "# for Loop of Epochs\n",
        "for i in range(epochs):\n",
        "  trn_corr = 0\n",
        "  tst_corr = 0\n",
        "\n",
        "  # Train\n",
        "  for b, (X_train, y_train) in enumerate(train_loader):\n",
        "    b = b+1 # start our batchs at 1\n",
        "    y_pred = model(X_train) # get predicted value from the training set, Not flattened\n",
        "    loss = criterion(y_pred, y_train) # how off are we? cmpare the parameters to correct\n",
        "\n",
        "    predicted = torch.max(y_pred.data,1)[1]\n",
        "    batch_corr = (predicted == y_train).sum()\n",
        "    trn_corr += batch_corr\n",
        "\n",
        "    # update our parameters\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # print out some results\n",
        "    if b%600 == 0:\n",
        "      print(f'epoch: {i}  batch: {b}  loss: {loss.item()}  \\\n",
        "      accuracy: {trn_corr.item()*100/(10*b)}%')\n",
        "    # Train\n",
        "  train_losses.append(loss)\n",
        "  train_correct.append(trn_corr)\n",
        "\n",
        "    # Test\n",
        "  with torch.no_grad():\n",
        "    for b, (X_test, y_test) in enumerate(test_loader):\n",
        "      y_val = model(X_test)\n",
        "      predicted = torch.max(y_val.data,1)[1] # Adding up correct predictions\n",
        "      tst_corr += (predicted == y_test).sum() # T=1 F=0 and sum away\n",
        "\n",
        "\n",
        "  loss = criterion(y_val, y_test)\n",
        "  test_losses.append(loss)\n",
        "  test_correct.append(tst_corr)\n",
        "\n",
        "\n",
        "current_time = time.time()\n",
        "total = current_time - start_time\n",
        "print(f'total time: {total/60} minutes')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoYFq1WSEB1K",
        "outputId": "cd2f77c2-3eac-4912-94cb-887c60275389"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0  batch: 600  loss: 0.3004239499568939        accuracy: 87.25%\n",
            "epoch: 0  batch: 1200  loss: 0.6581100225448608        accuracy: 90.25%\n",
            "epoch: 0  batch: 1800  loss: 0.37946993112564087        accuracy: 91.74444444444444%\n",
            "epoch: 0  batch: 2400  loss: 0.149811789393425        accuracy: 92.625%\n",
            "epoch: 0  batch: 3000  loss: 0.005510914605110884        accuracy: 93.28%\n",
            "epoch: 0  batch: 3600  loss: 0.2897501289844513        accuracy: 93.81111111111112%\n",
            "epoch: 0  batch: 4200  loss: 0.13308404386043549        accuracy: 94.20714285714286%\n",
            "epoch: 0  batch: 4800  loss: 0.016969826072454453        accuracy: 94.52708333333334%\n",
            "epoch: 0  batch: 5400  loss: 0.16984859108924866        accuracy: 94.87037037037037%\n",
            "epoch: 0  batch: 6000  loss: 0.020191635936498642        accuracy: 95.12666666666667%\n",
            "epoch: 1  batch: 600  loss: 0.029463794082403183        accuracy: 97.73333333333333%\n",
            "epoch: 1  batch: 1200  loss: 0.027131149545311928        accuracy: 97.55%\n",
            "epoch: 1  batch: 1800  loss: 0.0003603386285249144        accuracy: 97.68888888888888%\n",
            "epoch: 1  batch: 2400  loss: 0.006952356547117233        accuracy: 97.675%\n",
            "epoch: 1  batch: 3000  loss: 0.055465687066316605        accuracy: 97.73333333333333%\n",
            "epoch: 1  batch: 3600  loss: 0.08163018524646759        accuracy: 97.78611111111111%\n",
            "epoch: 1  batch: 4200  loss: 0.00803043320775032        accuracy: 97.83571428571429%\n",
            "epoch: 1  batch: 4800  loss: 0.009859224781394005        accuracy: 97.85416666666667%\n",
            "epoch: 1  batch: 5400  loss: 0.019804511219263077        accuracy: 97.8425925925926%\n",
            "epoch: 1  batch: 6000  loss: 0.002623599022626877        accuracy: 97.87666666666667%\n",
            "epoch: 2  batch: 600  loss: 0.0425240658223629        accuracy: 98.73333333333333%\n",
            "epoch: 2  batch: 1200  loss: 0.000948962289839983        accuracy: 98.73333333333333%\n",
            "epoch: 2  batch: 1800  loss: 0.0002476609661243856        accuracy: 98.72777777777777%\n",
            "epoch: 2  batch: 2400  loss: 0.004294014535844326        accuracy: 98.6%\n",
            "epoch: 2  batch: 3000  loss: 0.0008627338102087379        accuracy: 98.63666666666667%\n",
            "epoch: 2  batch: 3600  loss: 0.00037367860204540193        accuracy: 98.62222222222222%\n",
            "epoch: 2  batch: 4200  loss: 0.07970480620861053        accuracy: 98.61666666666666%\n",
            "epoch: 2  batch: 4800  loss: 0.4435266852378845        accuracy: 98.63333333333334%\n",
            "epoch: 2  batch: 5400  loss: 0.00044394185533747077        accuracy: 98.63888888888889%\n",
            "epoch: 2  batch: 6000  loss: 0.001704149297438562        accuracy: 98.62666666666667%\n",
            "epoch: 3  batch: 600  loss: 0.00026927117141894996        accuracy: 98.93333333333334%\n",
            "epoch: 3  batch: 1200  loss: 0.2184033840894699        accuracy: 98.91666666666667%\n",
            "epoch: 3  batch: 1800  loss: 0.18463851511478424        accuracy: 98.90555555555555%\n",
            "epoch: 3  batch: 2400  loss: 0.04778730124235153        accuracy: 98.89166666666667%\n",
            "epoch: 3  batch: 3000  loss: 0.006532914936542511        accuracy: 98.88333333333334%\n",
            "epoch: 3  batch: 3600  loss: 0.07989509403705597        accuracy: 98.875%\n",
            "epoch: 3  batch: 4200  loss: 0.0039350613951683044        accuracy: 98.87619047619047%\n",
            "epoch: 3  batch: 4800  loss: 0.12746575474739075        accuracy: 98.81875%\n",
            "epoch: 3  batch: 5400  loss: 0.05009021610021591        accuracy: 98.83333333333333%\n",
            "epoch: 3  batch: 6000  loss: 0.00020576473616529256        accuracy: 98.81166666666667%\n",
            "epoch: 4  batch: 600  loss: 0.00043912907131016254        accuracy: 99.18333333333334%\n",
            "epoch: 4  batch: 1200  loss: 1.6879748727660626e-05        accuracy: 99.19166666666666%\n",
            "epoch: 4  batch: 1800  loss: 0.00446991715580225        accuracy: 99.27777777777777%\n",
            "epoch: 4  batch: 2400  loss: 0.0004400695615913719        accuracy: 99.19166666666666%\n",
            "epoch: 4  batch: 3000  loss: 0.0001619629329070449        accuracy: 99.16333333333333%\n",
            "epoch: 4  batch: 3600  loss: 3.56410673703067e-05        accuracy: 99.11111111111111%\n",
            "epoch: 4  batch: 4200  loss: 0.0008625147747807205        accuracy: 99.07857142857142%\n",
            "epoch: 4  batch: 4800  loss: 0.0005345757817849517        accuracy: 99.05%\n",
            "epoch: 4  batch: 5400  loss: 0.0004711876972578466        accuracy: 99.0425925925926%\n",
            "epoch: 4  batch: 6000  loss: 0.018474875018000603        accuracy: 99.03666666666666%\n",
            "total time: 3.021400527159373 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_correct"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDGhuXdyOaQ5",
        "outputId": "e02edf7e-6f92-49ba-8249-c3fa6afb095b"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor(9729), tensor(9828), tensor(9867), tensor(9844), tensor(9851)]"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model(X_train)"
      ],
      "metadata": {
        "id": "r12iHqeSPmFh"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.max(y_pred.data,1)[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6738TmpPnt2",
        "outputId": "2e8143e5-6ee9-417b-b1ef-2c1d72433735"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2, 2, 3, 6, 2, 6, 6, 1, 7, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.max(y_pred.data,1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IXXMCLxQahp",
        "outputId": "e6121a0c-d0f1-40c8-a863-a6a61843633e"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.return_types.max(\n",
              "values=tensor([-3.5166e-05, -1.9799e-04, -1.5945e-01, -2.9325e-05, -4.0857e-04,\n",
              "        -4.0118e-04, -7.1526e-07, -3.1948e-05, -3.9841e-03,  0.0000e+00]),\n",
              "indices=tensor([2, 2, 3, 6, 2, 6, 6, 1, 7, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbPAayTjTllB",
        "outputId": "b49b470c-7cbc-4eec-a16a-74d4cad65dab"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2, 2, 3, 6, 2, 6, 6, 1, 7, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_corr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0YvbaYGUYoA",
        "outputId": "54ee9af8-3618-4c4d-a3d7-d74411770831"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(10)"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    }
  ]
}